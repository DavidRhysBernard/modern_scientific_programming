{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis (2)\n",
    "\n",
    "Here we discuss the steps which precede the text mining part in itself. That is mostly about how one extracts and prepare the data.\n",
    "For an introduction to the modeling part and NLP I suggest:\n",
    "- scikit-tutorial part 2\n",
    "- *Natural Language Processing with Python* by Steven Bird, Ewan Klein and Edward Loper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files\n",
    "- command line\n",
    "- requests\n",
    "\n",
    "## Crawl the web\n",
    "\n",
    "If page contain javascript code (links, dynamic text, ...), it become necessary to use a special software to \"fake\" a real navigation.\n",
    "Check:\n",
    "- selenium\n",
    "- phantomJS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text extraction: analyse html file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option 1: convert to text (htmltotext) + regex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option 2: by using the webpage structure\n",
    "\n",
    "Some more languages:\n",
    "    - html\n",
    "    - xml\n",
    "    - css\n",
    "\n",
    "Html pages have a dom object\n",
    "    \n",
    "XML and CSS provide a way to access particular elements of a webpage. Use developer tools in Chrome to get the right path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the text data\n",
    "\n",
    "- small data: \n",
    "\n",
    "    - python's `shelve` (like a dict, but on disk)\n",
    "    \n",
    "- big data: database\n",
    "\n",
    "    - mongodb: stores many documents as json documents, holds unstructured data easily\n",
    "    - sqlite: on-drive sql variant\n",
    "    - sql server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any model can be trained, the text must be transformed in an algorithm-friendly way, i.e. vectors of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "One naive approach consists in counting the number of occurrences of any given word, for all documents.\n",
    "\n",
    "|  _    | recession | france  | japan | fuji |\n",
    "|-------|-----------|---------|-------|------|\n",
    "| doc1  |  1        | 3       |  0    | 0    |\n",
    "| doc2  |  4        |  0      | 3     |  1   |\n",
    "| doc3  |  0        | 0       | 2     | 1    |\n",
    "\n",
    "There is a special fucntion for that, which operate on the whole data set:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "```\n",
    "\n",
    "\n",
    "This creates a potentially very large matrix, with many features. It is then required to store this matrix in a sparse format.\n",
    "\n",
    "Because, larger documents have more words, it is more informative to store frequencies, that is to divide by the total number of words in a document to obtain term frequencies (tf). One might also want to downscale words that appear in many documents, by dividing by overall frequency. This is called “Term Frequency times Inverse Document Frequency” (tf-idf). Both actions are supported by class:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "```\n",
    "\n",
    "Data is then ready to fit a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other approaches\n",
    "\n",
    "- tokenization (with python nltk)\n",
    "- phonetization\n",
    "- deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
